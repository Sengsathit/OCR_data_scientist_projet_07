{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Sengsathit/OCR_data_scientist_assets/main/header_pret_a_depenser.png\" alt=\"Alternative text\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurer Pandas pour un affichage complet du contenu des colonnes\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../../datasets/df_train_domain.csv')\n",
    "df_test = pd.read_csv('../../datasets/df_test_domain.csv')\n",
    "\n",
    "labels = df_train['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod√©lisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme des donn√©es d'entra√Ænement :  (307511, 244)\n",
      "Forme des donn√©es de test :  (48744, 244)\n"
     ]
    }
   ],
   "source": [
    "# Supprimer la cible des donn√©es d'entra√Ænement\n",
    "if 'TARGET' in df_train:\n",
    "    train = df_train.drop(columns = ['TARGET'])\n",
    "else:\n",
    "    train = df_train.copy()\n",
    "\n",
    "# Noms des caract√©ristiques\n",
    "features = list(train.columns)\n",
    "\n",
    "# Copie des donn√©es de test\n",
    "test = df_test.copy()\n",
    "\n",
    "# Imputation m√©diane des valeurs manquantes\n",
    "imputer = SimpleImputer(strategy = 'median')\n",
    "\n",
    "# Normaliser chaque caract√©ristique entre 0 et 1\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "# Ajuster sur les donn√©es d'entra√Ænement\n",
    "imputer.fit(train)\n",
    "\n",
    "# Transformer √† la fois les donn√©es d'entra√Ænement et de test\n",
    "train = imputer.transform(train)\n",
    "test = imputer.transform(df_test)\n",
    "\n",
    "# Transformer avec le scaler\n",
    "scaler.fit(train)\n",
    "train = scaler.transform(train)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "print('Forme des donn√©es d\\'entra√Ænement : ', train.shape)\n",
    "print('Forme des donn√©es de test : ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets d'entra√Ænement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'logistic_regression_best_model' already exists. Creating a new version of this model...\n",
      "2024/09/05 13:42:51 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: logistic_regression_best_model, version 3\n",
      "Created version '3' of model 'logistic_regression_best_model'.\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 426.31it/s]\n",
      "2024/09/05 13:42:51 INFO mlflow.tracking._tracking_service.client: üèÉ View run Run at: http://127.0.0.1:8080/#/experiments/407899967081860444/runs/a66e09d50143416da0ff43ddf521723d.\n",
      "2024/09/05 13:42:51 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/407899967081860444.\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er le mod√®le avec le param√®tre de r√©gularisation sp√©cifi√©\n",
    "logistic_regression = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# D√©finir la grille d'hyperparam√®tres\n",
    "params_grid = {'C': [0.0001, 0.001, 0.01]}\n",
    "\n",
    "# Configuration de GridSearchCV, avec 'roc_auc' comme m√©trique de scoring\n",
    "grid_search = GridSearchCV(logistic_regression, params_grid, cv=5, scoring='roc_auc', return_train_score=True)\n",
    "\n",
    "# Ex√©cuter GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Extraire le meilleur mod√®le, ses hyperparam√®tres et son score AUC\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_auc = grid_search.best_score_\n",
    "\n",
    "# Session MLflow\n",
    "mlflow.set_experiment(\"Logistic Regression\")\n",
    "\n",
    "# D√©marrer une nouvelle ex√©cution pour le meilleur mod√®le\n",
    "with mlflow.start_run(run_name=\"Run\"):\n",
    "    # Loguer les hyperparam√®tres du meilleur mod√®le\n",
    "    mlflow.log_param('C', best_params['C'])\n",
    "\n",
    "    # Calculer et loguer l'AUC pour le train et le test\n",
    "    y_pred_train_proba = best_model.predict_proba(X_train)[:, 1]\n",
    "    y_pred_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    auc_train = roc_auc_score(y_train, y_pred_train_proba)\n",
    "    auc_test = roc_auc_score(y_test, y_pred_test_proba)\n",
    "    \n",
    "    mlflow.log_metric('auc_train', auc_train)\n",
    "    mlflow.log_metric('auc_test', auc_test)\n",
    "\n",
    "    # Loguer le mod√®le pour la meilleure configuration\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=best_model,\n",
    "        artifact_path='logistic_regression_best_model_path',\n",
    "        signature=infer_signature(X_train, best_model.predict(X_train)),\n",
    "        input_example=X_train[:1],\n",
    "        registered_model_name=\"logistic_regression_best_model\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns = 'TARGET')\n",
    "\n",
    "features_name = list(df_train.columns)\n",
    "\n",
    "# Imputer les valeurs manquantes\n",
    "imputer = SimpleImputer(strategy = 'median')\n",
    "features_train = imputer.fit_transform(df_train)\n",
    "features_test = imputer.transform(df_test)\n",
    "\n",
    "# Normaliser les caract√©ristiques\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "features_train = scaler.fit_transform(features_train)\n",
    "features_test = scaler.transform(features_test)\n",
    "\n",
    "# Instance de mod√®le Random Forest Classifier\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)\n",
    "\n",
    "# Entra√Æner le mod√®le sur les donn√©es d'entra√Ænement\n",
    "random_forest_classifier.fit(features_train, train_labels)\n",
    "\n",
    "# Extraire les feature importances\n",
    "feature_importance_values = random_forest_classifier.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': features_name, 'importance': feature_importance_values})\n",
    "\n",
    "# Faire des pr√©dictions sur les donn√©es de test\n",
    "predictions = random_forest_classifier.predict_proba(features_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame des pr√©dictions\n",
    "submit = df_test[['SK_ID_CURR']]\n",
    "submit['TARGET'] = predictions\n",
    "\n",
    "# Sauvegarder les pr√©dictions\n",
    "submit.to_csv('../../datasets/output/random_forest_baseline_domain.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpr√©tation du mod√®le : Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(df):\n",
    "    \"\"\"\n",
    "    Trace les importances retourn√©es par un mod√®le.\n",
    "    \n",
    "    Args:\n",
    "        df (dataframe) : importances des caract√©ristiques. Doit contenir les \n",
    "        caract√©ristiques dans une colonne appel√©e `features` et les importances \n",
    "        dans une colonne appel√©e `importance`.\n",
    "        \n",
    "    Returns:\n",
    "        Affiche un graphique des 15 caract√©ristiques les plus importantes.\n",
    "        \n",
    "        df (dataframe) : importances des caract√©ristiques tri√©es par importance \n",
    "        (de la plus √©lev√©e √† la plus faible) avec une colonne pour l'importance normalis√©e.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Trier les caract√©ristiques en fonction de leur importance\n",
    "    df = df.sort_values('importance', ascending=False).reset_index()\n",
    "    \n",
    "    # Normaliser les importances des caract√©ristiques pour qu'elles totalisent un\n",
    "    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n",
    "\n",
    "    # Cr√©er un graphique √† barres horizontales des importances des caract√©ristiques\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    # Il est n√©cessaire d'inverser l'index pour afficher les plus importantes en haut\n",
    "    ax.barh(list(reversed(list(df.index[:15]))), \n",
    "            df['importance_normalized'].head(15), \n",
    "            align='center', edgecolor='k')\n",
    "    \n",
    "    # D√©finir les graduations et √©tiquettes sur l'axe y\n",
    "    ax.set_yticks(list(reversed(list(df.index[:15]))))\n",
    "    ax.set_yticklabels(df['feature'].head(15))\n",
    "    \n",
    "    # √âtiquetage du graphique\n",
    "    plt.xlabel('Importance Normalis√©e'); plt.title('Feature Importances')\n",
    "    plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des feature importances\n",
    "feature_importances_sorted = plot_feature_importances(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light Gradient Boosting Machine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
